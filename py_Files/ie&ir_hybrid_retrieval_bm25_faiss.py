# -*- coding: utf-8 -*-
"""IE&IR_Hybrid Retrieval_BM25_FAISS.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1YGYNV2WPtrEt6exezsWgznL_frk_vrXg
"""

#Hybrid Retrieval: FAISS + BM25 + Reranker

#!pip install -q rank_bm25

import re
import json
from pprint import pprint

#faiss_index = faiss.read_index("derry_girls_faiss.index")
#with open("derry_girls_metadata.json", "r", encoding="utf-8") as f:
 #    indexed_lines = json.load(f)

file_path = "/content/drive/MyDrive/IR_Project/derry_girls_script/DERRY-GIRLS-SCRIPT.txt"

with open(file_path, "r", encoding="windows-1252") as file:
    raw_lines = file.readlines()

scene_pattern = re.compile(r"^\[(.*)\]$")
speaker_pattern = re.compile(r"^([A-Za-z0-9 ']+):")
action_pattern = re.compile(r"\((.*?)\)")

parsed_lines = []
scene = None
season = episode = None

for line_number, raw_line in enumerate(raw_lines):
    line = raw_line.strip()
    if not line:
        continue

    if "SEASON" in line.upper():
        season = line.strip()
        continue
    if "EPISODE" in line.upper():
        episode = line.strip()
        continue

    scene_match = scene_pattern.match(line)
    if scene_match:
        scene = scene_match.group(1).strip()
        parsed_lines.append({
            "id": len(parsed_lines),
            "line_number": line_number,
            "season": season,
            "episode": episode,
            "scene": scene,
            "speaker": None,
            "actions": [],
            "clean_text": None,
            "raw_line": line
        })
        continue

    speaker_match = speaker_pattern.match(line)
    if speaker_match:
        speaker = speaker_match.group(1).strip()
        dialogue_with_actions = line[len(speaker)+1:].strip()
    else:
        speaker = None
        dialogue_with_actions = line

    actions = action_pattern.findall(dialogue_with_actions)
    clean_text = action_pattern.sub("", dialogue_with_actions).strip()

    parsed_lines.append({
        "id": len(parsed_lines),
        "line_number": line_number,
        "season": season,
        "episode": episode,
        "scene": scene,
        "speaker": speaker,
        "actions": actions,
        "clean_text": clean_text if clean_text else None,
        "raw_line": line
    })

print("Parsed lines preview:")
pprint(parsed_lines[:15])
´´´

## 3. Generate embeddings
```python
from sentence_transformers import SentenceTransformer

model = SentenceTransformer("all-MiniLM-L6-v2")
documents = [line["clean_text"] for line in parsed_lines if line["clean_text"]]
document_embeddings = model.encode(documents)
```

## 4. Create and save FAISS index
```python
import faiss
import numpy as np

index = faiss.IndexFlatL2(document_embeddings.shape[1])
index.add(np.array(document_embeddings))

print(f"\nNumber of items in FAISS index: {index.ntotal}")

indexed_lines = [line for line in parsed_lines if line["clean_text"]]

index_path = "/content/drive/MyDrive/IR_Project/derry_girls_index/derry_girls_faiss.index"
metadata_path = "/content/drive/MyDrive/IR_Project/derry_girls_index/derry_girls_metadata.json"

faiss.write_index(index, index_path)

with open(metadata_path, "w", encoding="utf-8") as f:
    json.dump(indexed_lines, f, ensure_ascii=False, indent=2)

print(f"Saved FAISS index to: {index_path}")
print(f"Saved metadata to: {metadata_path}")
```

## 5. Build BM25 index
```python
from rank_bm25 import BM25Okapi

# Tokenize documents
tokenized_docs = [doc.lower().split() for doc in documents]
bm25 = BM25Okapi(tokenized_docs)
```

## 6. Hybrid search with reranking
```python
from sentence_transformers import CrossEncoder

query = "family conflict in the kitchen"

# FAISS semantic search
query_embedding = model.encode([query])
D, I = index.search(np.array(query_embedding), 10)
semantic_results = [(i, documents[i]) for i in I[0]]

# BM25 search
bm25_scores = bm25.get_scores(query.lower().split())
bm25_top = np.argsort(bm25_scores)[-10:][::-1]
bm25_results = [(i, documents[i]) for i in bm25_top]

# Combine and deduplicate
combined = {i: doc for i, doc in semantic_results + bm25_results}
rerank_input = [(query, doc) for doc in combined.values()]

# Rerank
reranker = CrossEncoder("cross-encoder/ms-marco-MiniLM-L-6-v2")
scores = reranker.predict(rerank_input)

ranked = sorted(zip(combined.keys(), combined.values(), scores), key=lambda x: x[2], reverse=True)

print("\nTop hybrid + reranked results:")
for idx, text, score in ranked[:5]:
    print(f"[ID {idx}] Score: {score:.4f} | {text}")
```

#add topk accuracy, precision, recall, f1 score